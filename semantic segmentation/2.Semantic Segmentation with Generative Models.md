# 2.Semantic Segmentation with Generative Models

## Abstract

### 现状

- 减少训练对人工标注数据集的依赖，用有限的标记数据达到很强的泛化能力，这是半监督的目标。

### 创新

- 提出一个使用生成图像和标签的生成性模型，来进行像素级别的区分任务

### 方法

- 训练生成对抗网络：联合图像标签分布，用大量无标签图像补偿少标签的样本
- 在SyleGAN2网络上构建框架，加强标签合成分支
- 在测试时的图像标注，通过编码网络和测试时优化器，然后从推理嵌入中生成标签

### 总结

- 在医疗图像分割和部分人脸分割，和基准相比，我们的方法展示了强大的域外泛化能力

## 1.Introduction

### 动机

- 深度网络需要大量数据，去实现高精度。但会有过拟合问题，然后是图像标注耗时、昂贵

### 意义

- 减少对训练数据的依赖，仍然达到极好的表现、强大的泛化能力

### 技术

- 通过最新的对比学习半监督训练，得到强大的特征提取器，然后只需少量标签，因为特征已经隐式编码了语义信息

### 问题

- 半监督学习不对输入数据的分布进行显示建模，造成过拟合，然后就是有标注的语义图像很少

### 贡献

- 提出了基于最新的StyleGAN2并允许半监督训练的模型。我们是第一个处理语义分割，使用纯生成方法直接对联合图像标签分布进行建模
- 在医疗和人脸图像数据上进行了验证，在半监督的设置下，我们的结果相同或更好比起基准
- 我们展示了强大的泛化能力在域外分割任务，并定性的展示了可解释的表现。

## 2.Related work

### Semi-Supervised Learning and Semantic Segmentation

- 我们方法是学习强大的特征来生成图像本身，而不是辅助pre-task
- 我们只使用对比对象并且不用交叉熵项，生成器建立联合p(x,y)模型
- 使用生成性模型作为测试时语义输出的解码器

### Generator Inversion

- 我们方法的关键部分就是GAN生成器的反演，在测试时推理出标记新图片潜在的嵌入

### Generative Models for Image Understanding

- GAN 生成器学习特征用于语义分割

## 3.Method

### overview

- GAN p(x,y)由z隐式定义，z是正态分布的潜在变量。x,y,z条件独立。
首先由编码器和test-time optimization推断它的嵌入z，然后合成标签，标注x

### motivation

- 只需少量样本：半监督
泛化性：对生成的，使用了正态分布

### model

- 生成器：基于StyleGAN2
判别器：Dr和Dm
编码器和W+ - 空间

## 5.Conclusion

### 提出一个完全生成性方法进行语义分割，基于SyleGAN2，允许半监督训练，并且展示了强大的泛化性

